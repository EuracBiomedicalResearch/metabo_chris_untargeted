---
title: "Normalization of the untargeted metabolomics data from CHRIS"
author: "Mar Garcia-Aloy, Johannes Rainer"
output:
  BiocStyle::html_document:
    toc: true
    number_sections: false
    toc_float: true
---

```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

startpoint <- Sys.time()
```

In this document we are going to normalize the data from the CHRIS study.


# Preliminaries

We define the specific parameters for the current study, we load all 
required libraries, and we set up the parallel processing.

## Parameters

```{r param, echo=TRUE}
polarity <- "POS" # specify "POS" or "NEG"
myseed <- 589
da <- 0.01

# DEFINE PATHS:
IMAGE_PATH <- paste0("images/", polarity, "/normalization/")
dir.create(IMAGE_PATH, showWarnings = FALSE)
```

## Libraries

```{r libraries, echo=TRUE, warning=FALSE}
library(doParallel)
library(xcms)
library(Rdisop)
library(CompoundDb)
library(CompMetaboTools)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(reshape2)
library(beeswarm)
library(DESeq2)
library(pander)
library(readxl)

source("R/dobox.R")
## source("R/flag_model_inj_range.R")
## source("R/flag_model_cat_count.R")
## source("R/flag_model_mean_residual.R")
source("R/apply_colgroup.R")
source("R/mean_if.R")
source("R/plot_slope.R")
## source("R/flag_model_coef_count.R")
```


## Parallel processing

```{r parallel-cluster, eval=TRUE}
ncores <- Sys.getenv("SLURM_JOB_CPUS_PER_NODE", 3)
register(bpstart(MulticoreParam(ncores)))
```


# Load data

Below we load the data already processed with XCMS. Note that we have to
change/update the path to the original mzML files in case the 
pre-processing was performed on a different computer (e.g. the cluster).

```{r data-load, echo=TRUE}
load(paste0("data/data_XCMS_filled_", polarity, ".RData"))

## Update the file path.
#if (length(validObject(xdata, test = TRUE)))
#    dirname(xdata) <- sub("/data/massspec/mzML/", MZML_PATH,
#                          dirname(xdata), fixed = TRUE)

xdata$batch <- factor(xdata$batch)
batch_margin <- c()
for(i in 1:length(levels(xdata$batch))){
  batch_margin <- 
    c(batch_margin, which(xdata$batch == levels(xdata$batch)[i])[
      length(which(xdata$batch == levels(xdata$batch)[i]))])
}
```


Next we extract the raw as well as the filled-in feature abundances 
with the `quantify` method. For features with multiple peaks the sum 
is built to create a final abundance (parameter `method = "sum"`).

```{r data-extract, echo = FALSE, results = "hide"}
res <- quantify(xdata, method = "sum", filled = FALSE)
assays(res)$raw_filled <- featureValues(xdata, method = "sum",
                                        filled = TRUE)
```

Below we load the Biocrates-based targeted metabolomics data.  
The data is organized by having metabolites in the dataâ€™s rows, 
samples in columns.

```{r biocrates, echo=TRUE}
injections <- read_xlsx("data/chris-files-annotated.xlsx")
injections <- injections[injections$sample_name %in% 
                           gsub(".mzML", "", res$sampleNames), ]
injections <- injections[order(injections$timestamp), ]

library(biochristes7500)
data(biochristes7500)
all(injections$sample_name == gsub(".mzML", "", res$sampleNames)) # T
biocrates <- concentrations(biochristes7500, blessing = "none")
biocrates <- biocrates[, colnames(biocrates) %in% injections$id]
std_bioc <- read.csv("data/stds_biocrates.csv", stringsAsFactors = FALSE)
std_bioc <- std_bioc[std_bioc$abbreviation != "X", ]
biocrates <- biocrates[rownames(biocrates) %in% std_bioc$analyte_name, ]
```


## Colouring factors

Here we define colors to be used for the various experimental groups
throughout the experiment.

```{r colors, echo=TRUE}
xdata$class <- factor(xdata$class)
col_class <- brewer.pal(length(levels(xdata$class)), "Set1")
names(col_class) <- levels(xdata$class)
sample_colors <- col_class[xdata$class]
plot(1, 1, xaxt = 'n', yaxt = 'n', bty = 'n', ylab = '', xlab = '', 
     xlim = 0:1, ylim = 0:1)
legend("topleft", legend = names(col_class),
       col = col_class, pch = 16, pt.cex = 2, cex = 2, 
       bty = 'n')

getPalette <- colorRampPalette(brewer.pal(9, "YlOrRd"))
col_batch <- getPalette(length(levels(xdata$batch)))
names(col_batch) <- levels(xdata$batch)
plot(1, 1, xaxt = 'n', yaxt = 'n', bty = 'n', ylab = '', xlab = '', 
     xlim = 0:1, ylim = 0:1)
legend("topleft", legend = names(col_batch),
       col = col_batch, pch = 16, #pt.cex = 2, cex = 2, 
       bty = 'n', ncol = 5)
```


## Standards library

Next we determine which features match to the set of compounds for which
retention time and most likely ion have been determined. 
To this end we get all features with their median retention time
within the expected retention time +/- 5 seconds and an m/z matching the 
m/z of the expected ion (+/- 50 ppm). If more than one feature is found 
for a standard, the one with the higher number of peaks is chosen, 
if none if found the retention time window is extended to +/- 10 seconds.  
All the detected features will be ploted in order to see which are good-quality features. 
They will be used in the later steps for evaluating the performance of the normalization.

```{r features-for-standards}
is_info <- read.table(
  "https://raw.githubusercontent.com/EuracBiomedicalResearch/lcms-standards/master/data/internal_standards.txt",
  sep = "\t", header = TRUE, as.is = TRUE)
is_info$mix <- 0
is_info$"HMDB.code" <- NA
is_info <- 
  subset(is_info, 
         select = c("mix", "name", "abbreviation", "HMDB.code", 
                    "formula", "POS", "NEG", "RT", "data_set", "sample", 
                    "operator", "version", "quality_POS", "quality_NEG"))

std_info <- read.table(
  "https://raw.githubusercontent.com/EuracBiomedicalResearch/lcms-standards/master/data/standards_dilution.txt",
  sep = "\t", header = TRUE, as.is = TRUE)

std_info <- rbind(is_info, std_info)
rm(is_info)

std_info <- std_info[!is.na(std_info[, polarity]), ]
std_info <- std_info[!is.na(std_info$RT), ]
rownames(std_info) <- 1:nrow(std_info)
std_info$mzneut = NA
std_info$mz_ion = NA
for (i in seq(nrow(std_info))) {
  if (grepl("C", std_info$formula[i])){
    std_info$mzneut[i] <- getMolecule(
      as.character(std_info$formula[i]))$exactmass
  } else {
    std_info$mzneut[i] = as.numeric(std_info$formula[i])
  }
  #' Calculate also the m/z
  std_info$mz_ion[i] <- unlist(
    mass2mz(std_info$mzneut[i],
            adduct = as.character(
              std_info[i, polarity])))
}

## Get for each standard a feature
std_info$feature_id <- NA_character_
for (i in seq(nrow(std_info))) {
  ft <- featureDefinitions(xdata, mz = std_info$mz_ion[i],
                           rt = std_info$RT[i] + c(-5, 5),
                           ppm = 50, type = "any")
  if (nrow(ft))
    std_info$feature_id[i] <- rownames(ft[
      order(ft$npeaks, decreasing = TRUE), ])[1]
  else {
    ft <- featureDefinitions(xdata, mz = std_info$mz_ion[i],
                             rt = std_info$RT[i] + c(-10, 10),
                             ppm = 50, type = "any")
    if (nrow(ft))
      std_info$feature_id[i] <- rownames(ft[
        order(ft$npeaks, decreasing = TRUE), ])[1]
  }
}

std_info$diff_rt <- std_info$RT -
  featureDefinitions(xdata)[std_info$feature_id, "rtmed"]
std_info <- std_info[!is.na(std_info$feature_id), ]
#rownames(std_info) <- std_info$HMDB.code

#std_info$is_ok <- FALSE
#std_info$peak_note <- NA_character_
#write.table(std_info, file = paste0("data/std_info_", polarity, ".txt"), 
#            row.names = FALSE, sep = "\t")
```


```{r features-for-standards-plot, eval=FALSE}
dr <- paste0(IMAGE_PATH, "peak_shape/")
dir.create(dr, recursive = TRUE, showWarnings = FALSE)

for (i in 1:nrow(std_info)) {
  chrs <- featureChromatograms(xdata, 
                               features = std_info$feature_id[i], 
                               expandRt = 10, filled = TRUE)
  pk_col <- col_class[chrs$class[chromPeaks(chrs)[, "sample"]]]
  
  png(file = paste0(dr, std_info$feature_id[i], ".png"), 
      width = 12, height = 8, units = "cm", res = 300, pointsize = 4)
  plot(chrs, peakPch = 16, 
       peakCol = paste0(pk_col, 80),
       peakBg = paste0(pk_col, 10))
  dev.off()
}
```


The table below lists the standards for which a feature was identified.

```{r standards-feature-table, echo = FALSE, results = "asis"}
T <- std_info[!is.na(std_info$feature_id), c("name", "quality_POS",
                                             "feature_id", "diff_rt")]
rownames(T) <- NULL
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Features for standards. Shown is the name, the",
                   " quality of the peak in the standards spike-in",
                   " experiment and the difference between the rt",
                   " in that and the present data set."))
```

For `r nrow(std_info)` standards a feature was detected/defined in the
present data set. 


# Raw data

Before performing any data normalization we also evaluate the raw signal.

Following [@irizarryComparisonAffymetrixGeneChip2006] we distinguish
between *accuracy* and *precision* in evaluation of normalization
efficiency. High accuracy means that reported differences are highly similar to
the *real* differences in abundances, while high precision means that the
variation between replicated measurements is low. Low accuracy on the other hand
means that the measured data over- or underestimates the *real* differences or
abundances in the data and low precision that repeated measurements of the same
entity in the same sample yields different abundances.  

To estimate the accuracy, we will use the targed measurements done with 
Biocrates kit and to estimate the precision the repeated measurements of the
QC samples. The tools and visualization for these are linear models
for the former (measured against quantified concentrations) and coefficient of
variation (CV) and relative log-abundances (RLA) for the later. Precision
estimates will be performed separately for features of known compounds
(standards) and for all detected features in the data set. 
Precision will be also evaluated using samples that were repeated in 
2 different batches (POS: 20170615-20170728; NEG: 20170609-20170623)  

First of all we calculate feature-wise RLA values considering the type of samples
(*blank*, *pool*, and *study_sample*) as grouping variable.

```{r raw-rla}
rla_raw <- rowRla(assay(res, "raw_filled"), group = res$class)
```

The plot below shows the distribution of RLA values per sample for the complete
data set.

```{r raw-rla-plot, fig.width = 16, fig.height = 6, fig.cap = "RLA of the raw data", echo = FALSE}
dobox(rla_raw, ylab = "RLA", main = "raw data", 
      col = col_class[res$class],
      border = paste0(col_class[res$class], 40))
legend("bottomleft", col = col_class, legend = names(col_class),
       h = TRUE, pch = 16)
```

Next we calculate CV values for each feature across QC samples.

```{r raw-rsd}
rsd_calculate <- function(x) {
  ## general
  cvs <- data.frame(rowRsd(x[, res$class == "pool"]))
  colnames(cvs) <- c("QC")
  for (btch in levels(res$batch)) {
    tmp <- data.frame(
      rowRsd(x[, res$class == "pool" & res$batch == btch])
    )
    colnames(tmp) <- paste(c("QC"),
                           btch, sep = "_b")
    cvs <- cbind(cvs, tmp)
  }
  cvs
}

cv_raw <- rsd_calculate(assay(res, "raw_filled"))
```

The table below lists the CV quantiles (across all features) for the QC samples.

```{r raw-rsd-table, results = "asis", echo = FALSE}
T <- quantile(cv_raw[, "QC"], na.rm = TRUE)
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = "Distribution of CV for QC samples (raw data).")
```

The percentage of features with a CV > 0.3 in QC samples is 
`r round(sum(cv_raw$QC > 0.3, na.rm = TRUE) / length(cv_raw$QC)*100,1)`%.

The next table shows the CV quantiles for the features associated with
standards.

```{r raw-rsd-table-standards, results = "asis", echo = FALSE}
T <- quantile(cv_raw[std_info$feature_id, "QC"], na.rm = TRUE)
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = paste0("Distribution of CV for QC samples ",
                              "(raw data, features for standards)."))
```

The percentage of known features with a CV > 0.3 in QC samples is 
`r round(sum(cv_raw[std_info$feature_id, "QC"] > 0.3, na.rm = TRUE) / length(cv_raw[std_info$feature_id, "QC"])*100,1)`%.  

The table below lists the absolute differences quantiles 
(across all features) for duplicated samples.

```{r raw-diff-table, results="asis"}
dplc <- injections[!is.na(injections$id),]
dplc <- dplc[dplc$id %in% dplc$id[duplicated(dplc$id)], ]
unique_id <- unique(dplc$id)

diff_calculate <- function(x){
  set.seed(myseed)
  dt <- imputeRowMinRand(
    x, method = "from_to",
    min_fraction = 1/2,
    min_fraction_from = 1/1000
  )
  
  dt <- dt[, gsub(".mzML", "", colnames(dt)) %in% dplc$sample_name]
  
  diff <- data.frame(matrix(ncol = length(unique_id), nrow = nrow(dt)))
  colnames(diff) <- unique_id
  rownames(diff) <- rownames(dt)
  for(i in 1:length(unique_id)){
    dt.tmp <- dt[, grep(unique_id[i], colnames(dt))]
    dt.tmp <- log2(dt.tmp)
    diff[,i] <- abs(dt.tmp[,1] - dt.tmp[,2])
  }
  diff$mean <- rowMeans(diff)
  diff
}
diff_raw <- diff_calculate(assay(res, "raw_filled"))
T <- quantile(diff_raw[, "mean"], na.rm = TRUE)
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = paste0("Distribution of absolute mean differences for ",
             "duplicated samples (raw data)."))
```


The next table shows the absolute differences quantiles for the features associated with
standards.

```{r raw-diff-table-standards, results = "asis", echo = FALSE}
T <- quantile(diff_raw[std_info$feature_id, "mean"], na.rm = TRUE)
pandoc.table(
  round(T, 3), style = "rmarkdown",
  caption = paste0("Distribution of absolute mean differences for ",
                   "duplicated samples (raw data, features for ",
                   "standards)."))
```


At last we compare quantified against measured concentrations for the 
known compounds included in the Biocrates kit.

The table below lists the slope from the linear models for the regression of the
measured abundances on the quantified concentrations per metabolite (a
value of 1 represents a perfect linear correlation between abundance and
concentration) and the R squared from these model fits.  

```{r raw-slopes-r-table, echo = FALSE, results = "asis"}
dt <- assay(res, "raw_filled")
acc_raw <- data.frame(matrix(nrow=0, ncol = 2))
colnames(acc_raw) <- c("raw_slope", "raw_R")
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    acc_raw[nrow(acc_raw)+1,] <- NA
    rownames(acc_raw)[nrow(acc_raw)] <- std_bioc$abbreviation[i]
    a <- log2(dt[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    acc_raw[nrow(acc_raw), 1] <- summary(lms)$coefficients[2] # slopes
    acc_raw[nrow(acc_raw), 2] <- summary(lms)$adj.r.squared # correlation 
  }
}
pandoc.table(
  round(acc_raw,3), style = "rmarkdown",
  caption = paste0("Results from the regression analysis of ",
                   "measured abundances on quantified concentrations; ",
                   "raw data."))
```


# Normalization

## Between-sample normalization

Between-sample normalization aims to remove global abundance differences
between samples due to variations in sample collection, extraction,
processing and possibly amount.

### Sum of signals

We're going to normalize the abundances based on the total sum of the
signal. This is one of the simplest approaches.

```{r sum, echo=TRUE}
sms <- colSums(assay(res, "raw_filled"), na.rm = TRUE)
nf_sum <- sms / median(sms)
nf_sum[res$class == "blank"] <- 1
dt_sum <- sweep(assay(res, "raw_filled"), MARGIN = 2, nf_sum, `/`)
```


### Median of signals

This method is based on the normalization according to the median
abundance per sample. This is also one of the simplest approaches.

```{r median, echo=TRUE}
mdn <- colMedians(assay(res, "raw_filled"), na.rm = TRUE)
nf_mdn <- mdn / median(mdn)
nf_mdn[res$class == "blank"] <- 1
dt_mdn <- sweep(assay(res, "raw_filled"), MARGIN = 2, nf_mdn, `/`)
```


### Evaluation of normalization performance

Next we evaluate the performance of each normalization procedure based on the
coefficient of variation within QC samples.

```{r between-sample-rsd-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data."}
cv_sum <- rsd_calculate(dt_sum)
cv_mdn <- rsd_calculate(dt_mdn)

tmp <- data.frame(
  raw = cv_raw$QC,
  sum = cv_sum$QC,
  mdn = cv_mdn$QC
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "CV", xlab = "")
grid(nx = NA, ny = NULL)
abline(h = 0.3, lty = 2)

```

Between-sample normalization slightly reduced the coefficient of variation in QC samples. 

The table below summarizes this information.

```{r between-sample-rsd-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "between sample normalization (all features). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))
```

This evaluation was also performed separately for each batch 
(see the images saved in the corresponding folder).

```{r between-sample-rsd-per-batch, echo = FALSE}
dr <-  paste0(IMAGE_PATH, "between-sample-rsd-boxplot/")
dir.create(dr, showWarnings = FALSE)
dr <-  paste0(dr, "all_feat/")
dir.create(dr, showWarnings = FALSE)
for (i in levels(res$batch)) {
  tmp <- data.frame(
    raw = cv_raw[, paste0("QC_b", i)],
    sum = cv_sum[, paste0("QC_b", i)],
    mdn = cv_mdn[, paste0("QC_b", i)]
  )
  png(filename = paste0(dr, "batch_", i, ".png"),
      width = 10, height = 8, units = "cm", res = 300, pointsize = 4)
  par(mar = c(7, 4.3, 1, 1))
  boxplot(tmp, las = 2, 
          ylab = "CV", xlab = "", main = paste0("batch ", i))
  grid(nx = NA, ny = NULL)
  abline(h = 0.3, lty = 2)
  dev.off()
}
```

Next we evaluate impact of the normalization on the CV for only features
associated with the (main ion) of the standards.

```{r between-sample-rsd-boxplot-std, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 8, fig.cap = "Coefficient of variation (distribution across features for standards) for the raw and normalized data."}
tmp <- data.frame(
  raw = cv_raw[std_info$feature_id, "QC"],
  sum = cv_sum[std_info$feature_id, "QC"],
  mdn = cv_mdn[std_info$feature_id, "QC"]
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "CV", xlab = "", main = "std features")
grid(nx = NA, ny = NULL)
abline(h = 0.3, lty = 2)
```

Between-sample normalization also reduced the coefficient of variation for QC samples 
for features most likely detecting the main ion of a standard. 

The table below summarizes this information.

```{r between-sample-rsd-table-std, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "between sample normalization (std features). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))

dr <-  paste0(IMAGE_PATH, "between-sample-rsd-boxplot/std_feat/")
dir.create(dr, showWarnings = FALSE)
for (i in levels(res$batch)) {
  tmp <- data.frame(
    raw = cv_raw[std_info$feature_id, paste0("QC_b", i)],
    sum = cv_sum[std_info$feature_id, paste0("QC_b", i)],
    mdn = cv_mdn[std_info$feature_id, paste0("QC_b", i)]
  )
  png(filename = paste0(dr, "batch_", i, ".png"),
      width = 10, height = 8, units = "cm", res = 300, pointsize = 4)
  par(mar = c(7, 4.3, 1, 1))
  boxplot(tmp, las = 2, 
          ylab = "CV", xlab = "", main = paste0("batch ", i))
  grid(nx = NA, ny = NULL)
  abline(h = 0.3, lty = 2)
  dev.off()
}
```

We also evaluate the performance of each normalization procedure based on the
mean absolute differences in feature intensities within duplicated samples.

```{r between-sample-diff-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data."}
diff_sum <- diff_calculate(dt_sum)
diff_mdn <- diff_calculate(dt_mdn)

tmp <- data.frame(
  raw = diff_raw$mean,
  sum = diff_sum$mean,
  mdn = diff_mdn$mean
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "mean(diff)", xlab = "")
grid(nx = NA, ny = NULL)
```

Between-sample normalization slightly reduced the mean absolute differences 
in the feature intensiteis of duplicated samples. 

The table below summarizes this information.

```{r between-sample-diff-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(
  round(T, 3), style = "rmarkdown",
  caption = paste0("Quantiles for the mean of absolute differences for",
                   " duplicated samples before and after ",
                   "between sample normalization (all features). "))
```

Next we evaluate impact of the normalization on the mean of absolute 
differences for only features associated with the (main ion) of the standards.

```{r between-sample-diff-boxplot-std, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 8, fig.cap = "Coefficient of variation (distribution across features for standards) for the raw and normalized data."}
tmp <- data.frame(
  raw = diff_raw[std_info$feature_id, "mean"],
  sum = diff_sum[std_info$feature_id, "mean"],
  mdn = diff_mdn[std_info$feature_id, "mean"]
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "mean(diff)", xlab = "", main = "std features")
grid(nx = NA, ny = NULL)
```

Between-sample normalization also reduced the mean of absolute differences 
for duplicated samples for features most likely detecting the main ion of a standard. 

The table below summarizes this information.

```{r between-sample-diff-table-std, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = paste0("Quantiles for the mean of absolute differences for ",
                              "duplicated samples before and after ",
                              "between sample normalization (std features)."))
```


Next we evaluate the impact of the between-sample normalization on the accuracy
(i.e. the slopes from the quantification values of the metabolites included in Biocrates kit).

```{r between-sample-accuracy-table, echo = FALSE, results = "asis"}
acc_sum <- data.frame(matrix(nrow=0, ncol = 2))
colnames(acc_sum) <- c("sum_slope", "sum_R")
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    acc_sum[nrow(acc_sum)+1,] <- NA
    rownames(acc_sum)[nrow(acc_sum)] <- std_bioc$abbreviation[i]
    a <- log2(dt_sum[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    acc_sum[nrow(acc_sum), 1] <- summary(lms)$coefficients[2] # slopes
    acc_sum[nrow(acc_sum), 2] <- summary(lms)$adj.r.squared # correlation 
  }
}

acc_mdn <- data.frame(matrix(nrow=0, ncol = 2))
colnames(acc_mdn) <- c("mdn_slope", "mdn_R")
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    acc_mdn[nrow(acc_mdn)+1,] <- NA
    rownames(acc_mdn)[nrow(acc_mdn)] <- std_bioc$abbreviation[i]
    a <- log2(dt_mdn[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    acc_mdn[nrow(acc_mdn), 1] <- summary(lms)$coefficients[2] # slopes
    acc_mdn[nrow(acc_mdn), 2] <- summary(lms)$adj.r.squared # correlation 
  }
}

acc_tb <- cbind(acc_raw, acc_sum, acc_mdn)
pandoc.table(
  round(acc_tb,3), style = "rmarkdown", split.table = Inf,
  caption = paste0("Results from the regression analysis of ",
                   "measured abundances on quantified concentrations for ",
                   "raw and normalized data."))
```

Between-sample normalization slighly improve accuracy for some compounds. 
It seems that in this case the *sum* method it's a little bit better than the *median*.

### Summary

Between-sample normalization procedures slighly reduced the variability 
(the coefficient of variation) between replicated measurements (QC samples).   

Also a very low impact was observed on the slope representing the
regression/correlation of the measured intensity from the expected intensity for
quantified metabolites with the Biocrates kit.   

Thus, between-sample normalization slighly improved the
precision by reducing the between replicate variances (i.e. removing technical
variances) with also small improvements in accuracy.

Considering both the precision and the accuracy, we use the median scaling as
the best performing between-sample normalization method. 

```{r between-sample-summary}
assays(res)$norm_nofill <- sweep(assay(res, "raw"), MARGIN = 2, nf_mdn, `/`)
assays(res)$norm_filled <- sweep(assay(res, "raw_filled"), MARGIN = 2, nf_mdn, `/`)
```


## Within-batch

Next we perform a within-batch normalization to remove potential
injection order dependent signal drifts.

In order to define whether there is a similar injection order dependent
signal drift in each batch (i.e. the drift is independent of the batch)
we fit feature-wise linear models to the (log2 transformed) data of QC
samples within each batch and compare the slopes for each feature between
the batches (see the corresponding images in the folder *within-batch*).

```{r within-start}
injections <- injections[order(injections$timestamp), ]
all(injections$sample_name == gsub(".mzML", "", res$sampleNames)) # T
res$injection_idx <- NA
for(i in 1:length(levels(res$batch))){
  res$injection_idx[res$batch == levels(res$batch)[i]] <- 
    seq_len(length(which(res$batch == levels(res$batch)[i])))
}

lm_btch <- list()
slps_btch <- list()
for(i in levels(factor(xdata$batch))) {
  smps <- res$batch == i & res$class == "pool"
  lm_btch[[i]] <- xcms:::rowFitModel(
    y ~ inj_idx,
    y = log2(assay(res, "norm_nofill")[, smps]),
    method = "lmrob",
    data = data.frame(inj_idx = res$injection_idx[smps]))
  slps_btch[[i]] <- vapply(lm_btch[[i]], function(z)
    ifelse(any(!is.na(z)), z$coefficients[2], NA_real_), numeric(1))
}
```


```{r within-batch-correlation-slopes-batch}
# , fig.height = 12, fig.width = 8, fig.path = IMAGE_PATH
plts_by2 <- combn(seq(length(levels(factor(res$batch)))), 2)

dr <-  paste0(IMAGE_PATH, "within-batch/")
dir.create(dr, showWarnings = FALSE)
par(mfrow = c(4, 3),
    mar = c(4, 4, 2, 1)) 
for(i in seq(ncol(plts_by2))){
  if((length(slps_btch[[plts_by2[1,i]]]) != 
      sum(is.na(slps_btch[[plts_by2[1,i]]]))) &
     (length(slps_btch[[plts_by2[2,i]]]) != 
      sum(is.na(slps_btch[[plts_by2[2,i]]])))){
    png(filename = paste0(dr, "batch", plts_by2[1,i], "_batch", 
                          plts_by2[2,i], ".png"),
        width = 10, height = 8, units = "cm", res = 300, pointsize = 4)
    plot(slps_btch[[plts_by2[1,i]]], slps_btch[[plts_by2[2,i]]],
         pch = 16, col = "#00000040",
         xlab = paste("batch ", plts_by2[1,i]),
         ylab = paste("batch ", plts_by2[2,i]))
    grid()
    lmod <- lm(slps_btch[[plts_by2[2,i]]] ~ slps_btch[[plts_by2[1,i]]])
    abline(lmod, lty = 2)
    dev.off()
  }
}
```

For most of batches there is only a very low correlation of the slopes
between them (e.g., in POS: B1 *vs* B23-B38-B57), suggesting that the injection
dependent signal drift is for the most part batch-dependent.
In other cases (e.g., in POS: B6-B42, B17-B30), there is an important
correlation of the slopes between them, suggesting that the signal drift
was common among them.
However, since in some cases it seems that the signal drift is
batch-dependent, we're going to apply this normalization method for each
batch separately.

Next we fit the linear models describing an (log scale) injection index
dependent signal drift to abundances separately for each batch. The
advantage of the separate analysis is that the analysis in one batch is
not dependent also on the number of valid measurements of the feature
also in the other batch. Below we fit linear models `y ~ inj_idx` to the
log2 transformed abundances (only of detected peaks) using robust
regression [@Koller:2017jsa]. Model fitting is skipped for features with
less than 6 valid signals (the total number of QC samples per batch is 10).

```{r within-batch-model-fit}
mdls <- withinBatchFit(res[,res$class == "pool"], 
                       batch = res$batch[res$class == "pool"], 
                       assay = "norm_nofill", 
                       model = y ~ injection_idx, method = "lmrob",
                       minVals = 6)
```

We next remove fitted linear models for features for which valid measurements do
not span at least 3/4 of the injection index range.

```{r within-batch-flag-mdls}
## Defining the injection range on the full data set - assuming the
## same injection setup
inj_range <- diff(range(res$injection_idx))

mdls <- lapply(mdls, FUN = dropModels, FLAG_FUN = flag_model_inj_range,
               min_range = inj_range * 3/4, column = "injection_idx")
```

```{r within-batch-model-fit-plot, echo = FALSE}
#fig.width = 10, fig.height = 15, fig.path = IMAGE_PATH, 
# fig.cap = "Distribution of slopes from the models fitted to the data 
# to estimate the injection-order-dependent signal drift."

## Calculate slopes for models per batch.
slps <- lapply(mdls, function(x) {
  vapply(x, function(z) {
    if (length(z) > 1)
      coefficients(z)[2]
    else NA_real_
  }, numeric(1))
})

dr <- paste0(IMAGE_PATH, "slopes_batch_distribution/")
dir.create(dr, showWarnings = FALSE)
#par(mfrow = c(ceiling(sqrt(length(slps))), floor(sqrt(length(slps)))))
for (i in seq_along(slps)) {
  if(sum(is.na(slps[[i]])) < length(slps[[i]])){
    png(paste0(dr, "b_", names(slps)[i], ".png"), 
        width = 16, height = 7, res = 200, units = "cm", pointsize = 4)
    hist(slps[[i]], breaks = 128, xlab = "slope",
         main = paste("Batch", names(slps)[i]))
    dev.off() 
  }
}
```

Most of the slopes, that represent the estimated injection order-dependent
signal drift, are close to 0 suggesting most features not being affected by this
bias (see the corresponding images in the folder *slopes_batch_distribution*). 
Note that specifically the *injection index range filter* removed most of
the linear models with the largest estimated slopes/effects (mostly for the
first batch).

The table below lists the number of features for which the model was fitted and
the number of features for which model fitting was skipped or discarded.

```{r within-normalization-model-table, echo = FALSE, results = "asis"}
tab <- rbind(vapply(mdls, function(z) {
  c(`total features` = length(z),
    `excluded models` = sum(is.na(z)),
    `valid models` = sum(!is.na(z)))
}, integer(3)))
colnames(tab) <- paste("Batch", colnames(tab))

cptn <- paste("Numbers of features (per batch) for which an injection index ",
              "dependent model could be fitted.")
pandoc.table(t(tab), style = "rmarkdown", caption = cptn)
```

The number of features for which a model describing the injection dependent signal drift
was defined varies from 1/3 to half to 2/3 depending on the batch.



### Large injection order dependent drifts

Next we plot some examples for features with the largest injection
order-dependent signal drifts (see the plots saved in the fodler *largest_slopes*).

```{r within-batch-largest-slopes, echo = FALSE}
plot_feature_models <- function() {
  for (ft in fts) {
    mdl <- mdls_batch[[ft]]
    smpls <- res$batch == name_batch
    x <- res$injection_idx[smpls]
    y <- log2(assay(res, "norm_filled")[ft, smpls])
    y[is.na(y)] <- 0
    pch <- ifelse(
      is.na(assay(res, "norm_nofill")[ft, smpls]), yes = 1, no = 16)
    png(paste0(dr2, ft, ".png"), width = 16, height = 7, res = 200,
        units = "cm", pointsize = 4)
    par(mfrow = c(1, 2))
    plot_slope(x, y, mdl,
               col = paste0(col_class[res$class[smpls]], "80"),
               pch = pch, xaxt = "n", xlab = "",
               main = paste("Batch", name_batch))
    plot(1:ncol(res), log2(assay(res, "norm_nofill")[ft, ]),
         col = paste0(col_class[res$class], "80"),
         pch = 16, xaxt = "n", xlab = "", main = ft, ylab = "")
    abline(v = batch_margin, col = "grey", lty = 2)
    dev.off()
  }
}

## plot the top x features with the largest absolute slopes per batch.
dr <- paste0(IMAGE_PATH, "largest_slopes/")
dir.create(dr, showWarnings = FALSE)
top_x <- 20
for (i in seq_along(slps)) {
  slps_batch <- slps[[i]]
  name_batch <- names(slps)[[i]]
  mdls_batch <- mdls[[i]]
  fts <- names(slps_batch)[order(abs(slps_batch),
                                 decreasing = TRUE)][seq_len(top_x)]
  dr2 <- paste0(dr, "batch_", name_batch, "/")
  dir.create(dr2, showWarnings = FALSE)
  plot_feature_models()
}

```



### Highest R squared of model fit.

Next we create plots for features with the highest R squared of the model fit
per batch (see the plots saved in the fodler *largest_R2*).

```{r within-batch-feature-models-highest-R-squared, echo = FALSE}

## Calculate slopes for models per batch.
adjrs <- lapply(mdls, function(x) {
  vapply(x, function(z) {
    if (length(z) > 1)
      summary(z)$adj.r.squared
    else NA_real_
  }, numeric(1))
})

## plot the top x features
dr <- paste0(IMAGE_PATH, "largest_R2/")
dir.create(dr, showWarnings = FALSE)
top_x <- 20
for (i in seq_along(slps)) {
  slps_batch <- slps[[i]]
  name_batch <- names(slps)[[i]]
  mdls_batch <- mdls[[i]]
  adjrs_batch <- adjrs[[i]]
  fts <- names(adjrs_batch)[order(abs(adjrs_batch),
                                  decreasing = TRUE)][seq_len(top_x)]
  dr2 <- paste0(dr, "batch_", name_batch, "/")
  dir.create(dr2, showWarnings = FALSE)
  plot_feature_models()
}

```


### Adjustment for the injection-order-dependent signal drift

Next we apply the within batch correction adjusting all feature abundances
based on the estimated models.

```{r within-batch-normalization-adjust, message = FALSE, echo=TRUE}
res <- withinBatchAdjust(res, models = mdls, batch = res$batch,
                         assay = "norm_filled",
                         shiftNegative = "replaceHalfMin")
## Also define the non-filled-in normalized data
tmp <- assay(res, "norm_filled")
tmp[is.na(assay(res, "raw"))] <- NA
assays(res)$norm_nofill <- tmp
```


### Evaluation of normalization performance

Like after between-sample normalization, we evaluate again the performance of
the normalization procedure based on the coefficient of variation and the slope
of the linear model fits through the quantified metabolites.

```{r within-batch-rsd-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 6, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data (after within-batch normalization)."}
cv_norm <- rsd_calculate(assay(res, "norm_filled"))

tmp <- data.frame(
  raw = cv_raw$QC,
  norm = cv_norm$QC
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "CV", xlab = "")
grid(nx = NA, ny = NULL)
abline(h = 0.3, lty = 2)
```

Within-batch normalization sligthly reduced the coefficient of variation 
for QC samples.

The table below summarizes this information.

```{r within-batch-rsd-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "within-batch normalization (all features). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))
```

The coefficient of variation for the features corresponding to the main ion of
know compounds (standards).

```{r within-batch-rsd-standards-table, echo = FALSE, results = "asis"}
tmp <- data.frame(
  raw = cv_raw[std_info$feature_id, "QC"],
  norm = cv_norm[std_info$feature_id, "QC"]
)
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "within-batch normalization (standards). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))
```



```{r within-batch-rsd-standards-per-batch, echo = FALSE}
dr <- paste0(IMAGE_PATH, "within-batch-rsd-boxplot/")
dir.create(dr, showWarnings = FALSE)
for (i in levels(res$batch)) {
  tmp <- data.frame(
    raw = cv_raw[, paste0("QC_b", i)],
    norm = cv_norm[, paste0("QC_b", i)]
  )
  png(filename = paste0(dr, "batch_", i, ".png"),
      width = 7, height = 8, units = "cm", res = 300, pointsize = 4)
  par(mar = c(7, 4.3, 1, 1))
  boxplot(tmp, las = 2, 
          ylab = "CV", xlab = "", main = paste0("batch ", i))
  grid(nx = NA, ny = NULL)
  abline(h = 0.3, lty = 2)
  dev.off()
}

```

Again, we also evaluate the performance of the normalization procedure 
based on the mean of absolute differences in the intensities of duplicated samples.

```{r within-batch-diff-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 6, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data (after within-batch normalization)."}
diff_norm <- diff_calculate(assay(res, "norm_filled"))

tmp <- data.frame(
  raw = diff_raw$mean,
  norm = diff_norm$mean
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "mean(diff)", xlab = "")
grid(nx = NA, ny = NULL)
```

Within-batch normalization sligthly reduced the absolute mean differences 
of feature intensities for duplicated samples.

The table below summarizes this information.

```{r within-batch-diff-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = paste0("Quantiles for the mean differences for ",
                              "duplicated samples before and after ",
                              "within-batch normalization (all features)."))
```

The differences for the features corresponding to the main ion of
know compounds (standards).

```{r within-batch-diff-standards-table, echo = FALSE, results = "asis"}
tmp <- data.frame(
  raw = diff_raw[std_info$feature_id, "mean"],
  norm = diff_norm[std_info$feature_id, "mean"]
)
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(round(T, 3), style = "rmarkdown",
             caption = paste0("Quantiles for the mean differences for ",
                              "duplicated samples before and after ",
                              "within-batch normalization (standards)."))
```


Next we evaluate the impact of the between-sample normalization on the accuracy
(i.e. the slopes from the quantified metabolites).

```{r within-batch-accuracy-table, echo = FALSE, results = "asis"}
dt <- assay(res, "norm_filled")
acc_within <- data.frame(matrix(nrow=0, ncol = 2))
colnames(acc_within) <- c("norm_slope", "norm_R")
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    acc_within[nrow(acc_within)+1,] <- NA
    rownames(acc_within)[nrow(acc_within)] <- std_bioc$abbreviation[i]
    a <- log2(dt[std_info$feature_id[which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    acc_within[nrow(acc_within), 1] <- summary(lms)$coefficients[2] # slopes
    acc_within[nrow(acc_within), 2] <- summary(lms)$adj.r.squared # correlation 
  }
}

acc_tb <- cbind(acc_raw, acc_within)

pandoc.table(round(acc_tb,3), style = "rmarkdown", split.table = Inf,
             caption = paste0("Impact of within-batch normalization on ",
                              "accuracy. Shown are slopes and R squared for ",
                              "quantified of the raw data and " ,
                              "within-batch normalized data."))
```


### Summary

Similar to the between sample normalization, within-batch normalization 
slightly reduced the variability between replicated measurements 
(the coefficient of variation) and also had a very low impact on accuracy. 


## Between-batch

The between-batch normalization aims to remove batch specific effects from the
data. These batch effects are assumed to affect each sample measured in the same
batch (same run, from the same plate) in the same way. The effect is estimated
based on abundances in QC samples and differences of these are leveled between
batches. Note that this between-batch normalization does **not** account for
biases that result from pipetting or injection amount differences (unless these
are common to all samples measured in one batch). Such effects would have to be
normalized based on a between-sample normalization strategy.

Below we use linear models on (log2 transformed) detected signal in QC samples
to estimate the (per-feature) batch effect. We require at least 6 valid
measurements in QC samples of each batch from all features and mean absolute
residuals that are smaller than 0.5. Also, we flag features for which the ratio
of the average signal between study and QC samples differs by more than two-fold
between the batches. Assuming an unbiased sampling in both batches we expect
this signal to QC ratio the ratio to be comparable between the two batches. For
a considerable number of features this differs however between the batches. A
feature-wise normalization based on QC samples would introduce a bias instead of
removing it for these cases.

Features that do not fulfill the above mentioned criteria will be normalized
with a global model.

```{r between-batch-define}
qcs <- res$class == "pool"

## Use the linear model fit on DETECTED QC samples
if (!is.factor(res$batch))
  res$batch <- factor(res$batch)
mdls_batch <- xcms:::rowFitModel(
  y ~ batch,
  data = as.data.frame(colData(res))[qcs, ],
  y = log2(assay(res, "norm_nofill")[, qcs]),
  method = "lm", minVals = 6)

## Flag models for features with less than 6 values per batch.
mdls_batch <- dropModels(mdls_batch, FLAG_FUN = flag_model_cat_count,
                         variable = "batch", min_count = 6)

## Flag models with large residuals
mdls_batch <- dropModels(mdls_batch, FLAG_FUN = flag_model_mean_residual,
                         cut_off = 0.5)

## Flag models with <5 coefficients (ie, not 1 coefficient / batch)
mdls_batch <- dropModels(mdls_batch, FLAG_FUN = flag_model_coef_count,
                         n_coef = 5)

## Fit a global model on all features.
glbl_mdl_batch <- xcms:::fitModel(
  y ~ batch,
  data = as.data.frame(colData(res)[qcs, ]),
  y = log2(assay(res, "norm_nofill")[, qcs]),
  method = "lm", minVals = 6)

## Next we adjust the data applying the models estimated on the QC samples.
mdls_batch[is.na(mdls_batch)] <- list(glbl_mdl_batch)
```

At last we are applying the normalization to the between sample and within-batch
normalized data.

```{r between-batch-adjust}
tmp <- assay(res, "norm_filled")
tmp <- 2^xcms:::applyModelAdjustment(
  y = log2(tmp),
  data = as.data.frame(colData(res)),
  lmod = mdls_batch,
  shiftNegative = "replaceHalfMin")

tmp_nofill <- tmp
tmp_nofill[is.na(assay(res, "raw"))] <- NA

assays(res)$norm_filled <- tmp
assays(res)$norm_nofill <- tmp_nofill
```

```{r between-batch-check-plot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 10, fig.height = 15, fig.cap = "Effect of normalization for features with the strongest adjustment for between-batch bias. Shown are abundances of the raw data and of the normalized (between-sample, within-batch and between-batch)"}
## Check for some of the features with the largest slopes.
fts <- c()
for(i in 1:5){
  fts <- c(fts,
           which.max(abs(unlist(lapply(mdls_batch, function(x){
             if(length(x)>1) {
               x$coefficients[i]
             } else {NA}})))))
}
#fts <- c(paste0("FT0", fts[!duplicated(fts)]), features)
fts <- unique(c(gsub("\\..*", "", names(fts))))

par(mfrow = c(3, 2))
for(i in seq(length(fts))){
  ft <- fts[i]
  yr <- range(range(assay(res, "raw")[ft, ], na.rm = TRUE),
              range(assay(res, "norm_nofill")[ft, ], na.rm = TRUE))
  par(mar = c(0.5, 4.5, 2, 0))
  plot(x = seq_len(ncol(res)),
       y = log2(assay(res, "raw")[ft, ]),
       col = paste0(col_class[res$class], "80"),
       pch = 16, xaxt = "n", main = "Raw data",
       ylab = expression(log[2]~abundance), ylim = log2(yr))
  grid(nx = NA, ny = NULL)
  abline(v = batch_margin, col = "black", lty = 2)
  par(mar = c(0.5, 0.5, 2, 4))
  plot(x = seq_len(ncol(res)),
       y = log2(assay(res, "norm_nofill")[ft, ]),
       col = paste0(col_class[res$class], "80"),
       pch = 16, xaxt = "n", main = "Normalized data",
       ylim = log2(yr), yaxt = "n")
  grid(nx = NA, ny = NULL)
  abline(v = batch_margin, col = "black", lty = 2)
}

```


### Evaluation of normalization performance

At last we evaluate the performance of the normalization, which includes the
between-samples, within-batch and between-batch normalization based on different criteria.

First we evaluate the precision using the CV on pooled QC samples.

```{r between-batch-rsd-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 6, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data (after between-batch normalization)."}
cv_norm <- rsd_calculate(assay(res, "norm_filled"))

tmp <- data.frame(
  raw = cv_raw$QC,
  norm = cv_norm$QC
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "CV", xlab = "")
grid(nx = NA, ny = NULL)
abline(h = 0.3, lty = 2)
```

Normalization did reduce the CV for QC samples.

The table below summarizes this information.

```{r between-batch-rsd-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "(between-batch) normalization (all features). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))
```

The coefficient of variation for the features corresponding to the main ion of
know compounds (standards).

```{r between-batch-rsd-standards-table, echo = FALSE, results = "asis"}
tmp <- data.frame(
  raw = cv_raw[std_info$feature_id, "QC"],
  norm = cv_norm[std_info$feature_id, "QC"]
)
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
T <- rbind(T, `% CV > 0.3` = vapply(tmp, function(z)
  sum(z > 0.3, na.rm = TRUE) / length(z) * 100, numeric(1)))
pandoc.table(
  T, style = "rmarkdown",
  caption = paste0("Quantiles for the coefficient of variation for ",
                   "QC samples before and after ",
                   "(between-batch) normalization (standards). ",
                   "Also the percentage of features with a CV > ",
                   "0.3 is shown."))
```


We also evaluate the precision using the mean differences on duplciated samples.

```{r between-batch-diff-boxplot, echo = FALSE, fig.path = IMAGE_PATH, fig.width = 6, fig.height = 8, fig.cap = "Coefficient of variation (distribution across all features) for the raw and normalized data (after between-batch normalization)."}
diff_norm <- diff_calculate(assay(res, "norm_filled"))

tmp <- data.frame(
  raw = diff_raw$mean,
  norm = diff_norm$mean
)
par(mar = c(7, 4.3, 1, 1))
boxplot(tmp, las = 2, ylab = "mean(diff)", xlab = "")
grid(nx = NA, ny = NULL)
```

Normalization reduced the mean abs(differences) for duplicated samples.

The table below summarizes this information.

```{r between-batch-diff-table, echo = FALSE, results = "asis"}
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(
  round(T, 3), style = "rmarkdown",
  caption = paste0("Quantiles for the mean absolute differences for ",
                   "duplicated samples before and after ",
                   "(between-batch) normalization (all features)."))
```

The mean abs(differences) for the features corresponding to the main ion of
know compounds (standards).

```{r between-batch-diff-standards-table, echo = FALSE, results = "asis"}
tmp <- data.frame(
  raw = diff_raw[std_info$feature_id, "mean"],
  norm = diff_norm[std_info$feature_id, "mean"]
)
T <- do.call(cbind, lapply(tmp, quantile, na.rm = TRUE))
pandoc.table(
  round(T, 3), style = "rmarkdown",
  caption = paste0("Quantiles for the mean differences for ",
                   "duplicated samples before and after ",
                   "(between-batch) normalization (standards)."))
```


Next we evaluate the impact of the normalization on the accuracy
(i.e. the slopes from the quantified).

```{r between-batch-accuracy-table, echo = FALSE, results = "asis"}
dt <- assay(res, "norm_filled")
acc_within <- data.frame(matrix(nrow=0, ncol = 2))
colnames(acc_within) <- c("norm_slope", "norm_R")
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    acc_within[nrow(acc_within)+1,] <- NA
    rownames(acc_within)[nrow(acc_within)] <- std_bioc$abbreviation[i]
    a <- log2(dt[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    acc_within[nrow(acc_within), 1] <- summary(lms)$coefficients[2] # slopes
    acc_within[nrow(acc_within), 2] <- summary(lms)$adj.r.squared # correlation 
  }
}

acc_tb <- cbind(acc_raw, acc_within)

pandoc.table(
  round(acc_tb, 3), style = "rmarkdown", split.table = Inf,
  caption = paste0("Impact of within-batch normalization on ",
                   "accuracy. Shown are slopes and R squared for ",
                   "quantified of the raw data and " ,
                   "within-batch normalized data."))
```


# Summary

Summarizing, the applied normalization approach had a considerable effect on the
precision by reducing the CV, while maintaining the accuracy seen on the raw data.

Between-sample normalization and between-batch normalization had the biggest
influence on data quality.


```{r save}
set.seed(myseed)
dt <- imputeRowMinRand(assay(res, "raw_filled") , method = "from_to",
                       min_fraction = 1/2, min_fraction_from = 1/1000)
set.seed(myseed)
dt_norm <- imputeRowMinRand(assay(res, "norm_filled"), method = "from_to",
                            min_fraction = 1/2, min_fraction_from = 1/1000)

CV <- function(x)((100*sd(x))/(mean(x)))
idx <- which(res$class == "pool")
dr <- paste0(IMAGE_PATH, "precision/")
dir.create(dr, showWarnings = FALSE)
for(i in 1:nrow(std_info)){
  ythr <- max(c(dt[std_info$feature_id[i],],
                dt_norm[std_info$feature_id[i],]))
  png(filename = paste0(dr, std_info$abbreviation[i], ".png"), 
      width = 16, height = 7, res = 200, units = "cm", pointsize = 4)
  par(mfrow = c(1, 2), mar = c(0.5,2,1.5,0.5))
  plot(dt[std_info$feature_id[i],], pch=16, 
       col = paste0(col_class[res$class], 90), xlab = "", ylab = "", 
       main = "raw", ylim=c(0, ythr))
  lines(idx, dt[std_info$feature_id[i], idx], col = "grey")
  abline(v = batch_margin, col = "grey", lty = 2)
  text(1, ythr*0.9, pos = 4,
       paste0("CV=", round(CV(dt[std_info$feature_id[i], idx])), "%"))
  
  plot(dt_norm[std_info$feature_id[i],], pch=16, 
       col = paste0(col_class[res$class], 90), xlab = "", ylab = "", 
       main = "normalized", ylim=c(0, ythr))
  lines(idx, dt_norm[std_info$feature_id[i], idx], col = "grey")
  abline(v = batch_margin, col = "grey", lty = 2)
  text(1, ythr*0.9, pos = 4,
       paste0("CV=", round(CV(dt_norm[std_info$feature_id[i], idx])), "%"))
  dev.off()
}

dr <- paste0(IMAGE_PATH, "accuracy/")
dir.create(dr, showWarnings = FALSE)
for(i in 1:nrow(std_bioc)){
  if(std_bioc$abbreviation[i] %in% std_info$abbreviation){
    a <- log2(dt[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    b <- log2(biocrates[std_bioc$analyte_name[i],])
    common_names <- intersect(names(a), names(b))
    a <- a[common_names]
    b <- b[common_names]
    
    lms <- lm(a~b)
    png(filename = paste0(dr, std_bioc$abbreviation[i], ".png"), 
        width = 16, height = 7, res = 200, units = "cm", pointsize = 4)
    par(mfrow = c(1, 2), mar = c(4.5,4.5,1.5,0.5))
    plot(b, a, xlab = "Biocrates", ylab = "Untargeted", 
         main = paste0(std_bioc$abbreviation[i], ": raw"))
    abline(lm(a~b))
    text(min(b), min(a)*1.1, pos = 4, 
         paste0("slp = ", round(summary(lms)$coefficients[2],3), 
                "\n R2 = ", round(summary(lms)$adj.r.squared, 3)))
    
    a <- log2(dt_norm[std_info$feature_id[
      which(std_info$abbreviation == std_bioc$abbreviation[i])],])
    names(a) <- injections$id
    a <- a[common_names]
    lms <- lm(a~b)
    plot(b, a, xlab = "Biocrates", ylab = "Untargeted", 
         main = "normalized")
    abline(lm(a~b))
    text(min(b), min(a)*1.1, pos = 4, 
         paste0("slp = ", round(summary(lms)$coefficients[2],3), 
                "\n R2 = ", round(summary(lms)$adj.r.squared, 3)))
    dev.off()
  }
}

save(res, file = paste0("data/data_XCMS_norm_", polarity, ".RData"))
```


# Session information

```{r session-information}
Sys.time()-startpoint

devtools::session_info()
```

